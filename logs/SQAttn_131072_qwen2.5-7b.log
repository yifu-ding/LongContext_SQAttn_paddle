/home/usrname/miniconda/envs/sqattn/lib/python3.10/site-packages/paddle/utils/cpp_extension/extension_utils.py:718: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md
  warnings.warn(warning_message)
W1030 09:48:08.269000 3673762 site-packages/torch/utils/cpp_extension.py:2430] TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. 
W1030 09:48:08.269000 3673762 site-packages/torch/utils/cpp_extension.py:2430] If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'] to specific architectures.
2025-10-30 09:48:08,341 - INFO - flashinfer.jit: Prebuilt kernels not found, using JIT backend
None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.
/home/usrname/miniconda/envs/sqattn/lib/python3.10/site-packages/_distutils_hack/__init__.py:30: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml
  warnings.warn(
/home/usrname/miniconda/envs/sqattn/lib/python3.10/site-packages/jieba/_compat.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  import pkg_resources
Namespace(data_dir=PosixPath('ruler_eval_result/Qwen/Qwen2.5-7B-Instruct/synthetic/131072/SQAttn/data'), save_dir=PosixPath('ruler_eval_result/Qwen/Qwen2.5-7B-Instruct/synthetic/131072/SQAttn/pred'), benchmark='synthetic', task='vt', subset='validation', chunk_idx=0, chunk_amount=1, server_type='hf', server_host='127.0.0.1', server_port='5000', ssh_server=None, ssh_key_path=None, model_name='Qwen/Qwen2.5-7B-Instruct', attn_type='SQAttn', max_len=131072, batch_size=1, device='cuda:0', dtype='bf16', temperature=1.0, top_k=32, top_p=1.0, random_seed=0, sliding_window_size=None, threads=4, synthetic_len=131072, calib_dataset='longbench', nsamples=128, seqlen=2048, eval_ppl=True, eval_gsm8k=False, multigpu=False, tasks=None, num_fewshot=0, limit=-1, dynamic_shape=False, quant=True, qk_qtype='int', v_qtype='int', bit8_thres=0.75, bit4_thres=0.8, sample_output_file='gsm8k_res.jsonl', use_relative_distance=True, max_new_tokens=128, budget_ratio=0.018, estimate_ratio=0.232)
Predict vt 
from ruler_eval_result/Qwen/Qwen2.5-7B-Instruct/synthetic/131072/SQAttn/data/vt/validation.jsonl
to ruler_eval_result/Qwen/Qwen2.5-7B-Instruct/synthetic/131072/SQAttn/pred/vt.jsonl
[32m[2025-10-30 09:48:10,941] [    INFO][0m - Using download source: huggingface[0m
[32m[2025-10-30 09:48:11,274] [    INFO][0m - Using download source: huggingface[0m
[32m[2025-10-30 09:48:11,274] [    INFO][0m - Using download source: huggingface[0m
[32m[2025-10-30 09:48:11,274] [    INFO][0m - Loading configuration file /home/data/usrname/hf_cache/hub/models--Qwen--Qwen2.5-7B-Instruct/snapshots/a09a35458c702b33eeacc393d103063234e8bc28/config.json[0m
[32m[2025-10-30 09:48:11,274] [    INFO][0m - Using download source: huggingface[0m
[32m[2025-10-30 09:48:11,275] [    INFO][0m - We are using <class 'paddleformers.transformers.qwen2.modeling.Qwen2ForCausalLM'> to load 'Qwen/Qwen2.5-7B-Instruct'.[0m
[32m[2025-10-30 09:48:11,275] [    INFO][0m - Using download source: huggingface[0m
[32m[2025-10-30 09:48:11,275] [    INFO][0m - Loading configuration file /home/data/usrname/hf_cache/hub/models--Qwen--Qwen2.5-7B-Instruct/snapshots/a09a35458c702b33eeacc393d103063234e8bc28/config.json[0m
[32m[2025-10-30 09:48:11,275] [    INFO][0m - Using download source: huggingface[0m
[32m[2025-10-30 09:48:11,275] [    INFO][0m - Loading weights file from cache at /home/data/usrname/hf_cache/hub/models--Qwen--Qwen2.5-7B-Instruct/snapshots/a09a35458c702b33eeacc393d103063234e8bc28/model.safetensors.index.json[0m
[32m[2025-10-30 09:48:11,276] [    INFO][0m - Using download source: huggingface[0m
[32m[2025-10-30 09:48:11,276] [    INFO][0m - Using download source: huggingface[0m
[32m[2025-10-30 09:48:11,276] [    INFO][0m - Using download source: huggingface[0m
[32m[2025-10-30 09:48:11,276] [    INFO][0m - Using download source: huggingface[0m
W1030 09:48:11.529102 3673762 gpu_resources.cc:114] Please NOTE: device: 0, GPU Compute Capability: 9.0, Driver API Version: 12.8, Runtime API Version: 12.9
[32m[2025-10-30 09:48:11,557] [    INFO][0m - loss_subbatch_sequence_length: -1 , use_fused_head_and_loss_fn: False, use_filtered_label_loss: False[0m

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:  25%|██▌       | 1/4 [00:01<00:04,  1.66s/it]
Loading checkpoint shards:  50%|█████     | 2/4 [00:03<00:03,  1.64s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [00:04<00:01,  1.61s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.54s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [00:06<00:00,  1.57s/it]
[32m[2025-10-30 09:48:17,853] [    INFO][0m - All model checkpoint weights were used when initializing Qwen2ForCausalLM.
[0m
[32m[2025-10-30 09:48:17,853] [    INFO][0m - All the weights of Qwen2ForCausalLM were initialized from the model checkpoint at Qwen/Qwen2.5-7B-Instruct.
If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2ForCausalLM for predictions without further training.[0m
[32m[2025-10-30 09:48:17,856] [    INFO][0m - Using download source: huggingface[0m
[32m[2025-10-30 09:48:17,856] [    INFO][0m - Loading configuration file /home/data/usrname/hf_cache/hub/models--Qwen--Qwen2.5-7B-Instruct/snapshots/a09a35458c702b33eeacc393d103063234e8bc28/generation_config.json[0m
2025-10-30 09:48:18.259 | INFO     | attn_hub.sqattn.compress:compress_model:173 - Starting compression with 28 layers
2025-10-30 09:48:18.259 | INFO     | attn_hub.sqattn.compress:compress_model:174 - Phase 1: Preparing calibration data...
context_len: 131072, n_clusters: 8192, nprobe: 147, n_segments: 16
Allocate GPU buffers and CPU pin memory ...

Start prefilling ...
Prefill batch 0 of 1
[Prefill before] allocated=14.55 GB, reserved=14.58 GB on gpu:0
/home/usrname/miniconda/envs/sqattn/lib/python3.10/site-packages/paddle/utils/decorator_utils.py:420: Warning: 
Non compatible API. Please refer to https://www.paddlepaddle.org.cn/documentation/docs/en/develop/guides/model_convert/convert_from_pytorch/api_difference/torch/torch.split.html first.
  warnings.warn(

Prefilling latency: 1.0055 s

[sample 0] allocated=14.55 GB, reserved=14.58 GB on gpu:0
2025-10-30 09:48:19.692 | INFO     | attn_hub.sqattn.compress:compress_model:212 - Phase 2: Processing layers...

Compressing:   0%|          | 0/28 [00:00<?, ?it/s]
Compressing:  11%|█         | 3/28 [00:00<00:01, 23.82it/s]
Compressing:  21%|██▏       | 6/28 [00:00<00:01, 21.25it/s]
Compressing:  32%|███▏      | 9/28 [00:00<00:00, 20.54it/s]
Compressing:  43%|████▎     | 12/28 [00:00<00:00, 20.21it/s]
Compressing:  54%|█████▎    | 15/28 [00:00<00:00, 20.04it/s]
Compressing:  64%|██████▍   | 18/28 [00:00<00:00, 19.95it/s]
Compressing:  71%|███████▏  | 20/28 [00:00<00:00, 19.88it/s]
Compressing:  79%|███████▊  | 22/28 [00:01<00:00, 19.84it/s]
Compressing:  86%|████████▌ | 24/28 [00:01<00:00, 19.79it/s]
Compressing:  93%|█████████▎| 26/28 [00:01<00:00, 19.78it/s]
Compressing: 100%|██████████| 28/28 [00:01<00:00, 20.47it/s]
2025-10-30 09:48:21.060 | INFO     | attn_hub.sqattn.compress:compress_model:249 - Compression complete!

  0%|          | 0/1 [00:00<?, ?it/s]context_len: 131072, n_clusters: 8192, nprobe: 147, n_segments: 16
Allocate GPU buffers and CPU pin memory ...

Start prefilling ...
Prefill batch 0 of 1

Prefilling latency: 29.3735 s

Start decoding ...
Decoding latency: 54.62 ms/step, Throughput: 18.31 tokens/s
                    
Used time: 0.7 minutes
